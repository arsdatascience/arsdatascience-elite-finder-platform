// aiController.js - Implementation using OpenAI and Gemini
// Provider: OpenAI (Custom Endpoint /v1/responses) and Gemini (Google Generative AI)

const { ClaudeService, ClaudeModel } = require('./services/anthropicService');
const qdrantService = require('./services/qdrantService');
const db = require('./database');
const { decrypt } = require('./utils/crypto');
const { getTenantScope } = require('./utils/tenantSecurity');

const getEffectiveApiKey = async (provider = 'openai', userId = null) => {
  // 1. Try to get from User DB (SaaS Multi-tenant)
  if (userId) {
    try {
      const result = await db.query('SELECT openai_key, gemini_key, anthropic_key FROM users WHERE id = $1', [userId]);
      if (result.rows.length > 0) {
        const keys = result.rows[0];
        let userKey = null;
        if (provider === 'gemini' && keys.gemini_key) userKey = decrypt(keys.gemini_key);
        else if (provider === 'anthropic' && keys.anthropic_key) userKey = decrypt(keys.anthropic_key);
        else if ((provider === 'openai' || !provider) && keys.openai_key) userKey = decrypt(keys.openai_key);

        if (userKey) {
          console.log(`üîë Using User API Key for ${provider}`);
          return userKey;
        }
      }
    } catch (err) {
      console.error('Error fetching user API key:', err);
    }
  }

  // 2. Fallback to System Env Vars
  if (provider === 'gemini') {
    let apiKey = process.env.GEMINI_API_KEY;
    if (!apiKey) {
      const allKeys = Object.keys(process.env);
      const geminiKey = allKeys.find(k => k.includes('GEMINI') && k.includes('KEY'));
      if (geminiKey) apiKey = process.env[geminiKey];
    }
    return apiKey;
  } else if (provider === 'anthropic') {
    return process.env.ANTHROPIC_API_KEY;
  } else {
    let apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      const allKeys = Object.keys(process.env);
      const openaiKey = allKeys.find(k => k.includes('OPENAI') && k.includes('KEY'));
      if (openaiKey) apiKey = process.env[openaiKey];
    }
    return apiKey;
  }
};

// Helper to generate embeddings
const generateEmbeddings = async (text, apiKey) => {
  const API_URL = "https://api.openai.com/v1/embeddings";

  try {
    const response = await fetch(API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        input: text,
        model: "text-embedding-3-small"
      })
    });

    if (!response.ok) {
      throw new Error(`OpenAI Embedding Error: ${response.statusText}`);
    }

    const data = await response.json();
    return data.data[0].embedding;
  } catch (error) {
    console.error("Embedding Generation Failed:", error);
    return null;
  }
};

const redis = require('./redisClient'); // Ensure redis is imported at top if not already

const generateDashboardInsights = async (req, res) => {
  const { kpis, selectedClient, platform, dateRange, provider = 'openai' } = req.body;
  const userId = req.user ? req.user.id : null;
  const { isSuperAdmin, tenantId } = getTenantScope(req);

  // Cache Key Strategy: Hash of the input parameters to ensure uniqueness
  // Simple key: insight:tenant:client:dateStart:dateEnd
  const cacheKey = `ai_insight:${tenantId}:${selectedClient || 'all'}:${dateRange?.start || 'all'}:${dateRange?.end || 'all'}`;

  try {
    // 1. Check Cache
    const cachedInsight = await redis.get(cacheKey);
    if (cachedInsight) {
      console.log('‚ö° Serving AI Insight from Redis Cache');
      return res.json({ insight: cachedInsight });
    }

    // SAAS FIX: Try to get key from tenant owner if possible, or system fallback
    // For now, we use the logged user's key or system key. 
    // Ideally, we should check if the tenant has a specific key configured.
    const apiKey = await getEffectiveApiKey(provider, userId);

    if (!apiKey) {
      console.warn("‚ö†Ô∏è Dashboard Insight: No API Key found.");
      // Return a mock insight instead of error to prevent frontend spinner hang
      return res.json({ insight: "‚ö†Ô∏è API Key n√£o configurada. Configure a OPENAI_API_KEY no arquivo .env para receber insights reais." });
    }

    // 1. Analyze KPIs to form a search query
    let queryText = "Estrat√©gias gerais de marketing digital e otimiza√ß√£o de campanhas";
    const roiKpi = kpis.find(k => k.label.includes('ROI') || k.label.includes('ROAS'));
    const ctrKpi = kpis.find(k => k.label.includes('CTR'));
    const cpcKpi = kpis.find(k => k.label.includes('CPC'));

    if (roiKpi && roiKpi.trend === 'down') queryText = "Como recuperar ROI e ROAS em queda em campanhas de tr√°fego pago";
    else if (ctrKpi && ctrKpi.trend === 'down') queryText = "Como aumentar CTR e melhorar criativos saturados";
    else if (cpcKpi && cpcKpi.trend === 'up') queryText = "Estrat√©gias para reduzir CPC alto e melhorar √≠ndice de qualidade";

    console.log(`üîç Searching knowledge base for: "${queryText}"`);

    // 2. Generate Embedding for the query
    const queryVector = await generateEmbeddings(queryText, apiKey);

    // 3. Search in Qdrant (Fail-safe)
    let context = "";
    if (queryVector) {
      try {
        const searchResult = await qdrantService.searchVectors('marketing_strategies', queryVector, 3);
        if (searchResult.success && searchResult.results.length > 0) {
          context = searchResult.results.map(r => r.payload.content || r.payload.text).join("\n\n");
          console.log("üìö Knowledge Base Context Found:", searchResult.results.length, "items");
        }
      } catch (err) {
        console.warn("‚ö†Ô∏è Qdrant search failed (ignoring):", err.message);
      }
    }

    // 4. Generate Insight with LLM
    const prompt = `
      Atue como um Especialista S√™nior em Data Analytics e Marketing Digital.
      
      CONTEXTO DO CLIENTE:
      - Cliente ID: ${selectedClient}
      - Plataforma: ${platform}
      - Per√≠odo: ${dateRange.start} a ${dateRange.end}
      
      DADOS ATUAIS (KPIs):
      ${JSON.stringify(kpis)}

      BASE DE CONHECIMENTO RECUPERADA (RAG):
      ${context || "Nenhum contexto espec√≠fico encontrado na base vetorial. Use seu conhecimento geral avan√ßado."}

      TAREFA:
      Gere um insight t√©cnico, direto e acion√°vel sobre a situa√ß√£o atual.
      - Se houver problemas (quedas), explique a causa prov√°vel e a solu√ß√£o.
      - Se estiver est√°vel/crescendo, sugira o pr√≥ximo passo de escala.
      - Use terminologia t√©cnica correta (CPA, ROAS, LTV, Churn, etc).
      - M√°ximo de 2 frases.
      - Seja espec√≠fico, evite generalidades como "melhore seus an√∫ncios". Diga "Teste novos hooks nos primeiros 3s do v√≠deo".

      RESPOSTA (Apenas o texto do insight):
    `;

    const insight = await callOpenAI(prompt, apiKey, "gpt-4-turbo-preview", false);
    const finalInsight = insight.trim();

    // 5. Save to Cache (1 Hour - Insights don't change that fast)
    await redis.set(cacheKey, finalInsight, 'EX', 3600);

    res.json({ insight: finalInsight });

  } catch (error) {
    console.error("Dashboard Insight Generation Failed:", error);
    res.status(500).json({ error: "Failed to generate insight" });
  }
};




const formatChatHistory = (messages) => {
  return messages.map(m => `${m.sender.toUpperCase()}: ${m.text}`).join('\n');
};

// Helper function to call OpenAI API via standard /v1/chat/completions endpoint
const callOpenAI = async (prompt, apiKey, model = "gpt-4o", jsonMode = false) => {
  const API_URL = "https://api.openai.com/v1/chat/completions";

  // Fallback para gpt-4o se o modelo solicitado for gpt-5 (que n√£o existe publicamente)
  const safeModel = model.includes('gpt-5') ? 'gpt-4o' : model;

  const requestBody = {
    model: safeModel,
    messages: [
      { role: "user", content: prompt }
    ],
    temperature: 0.7
  };

  if (jsonMode) {
    requestBody.response_format = { type: "json_object" };
  }

  try {
    const response = await fetch(API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify(requestBody)
    });

    if (!response.ok) {
      const errorData = await response.text();
      throw new Error(`OpenAI API Error (${response.status}): ${errorData}`);
    }

    const data = await response.json();

    const content = data.choices?.[0]?.message?.content;

    if (!content) {
      console.error("Unknown response structure:", JSON.stringify(data, null, 2));
      throw new Error("Empty or unknown response structure from OpenAI API");
    }

    return content;

  } catch (error) {
    console.error("OpenAI API Call Failed:", error);
    throw error;
  }
};

// Helper function to call Gemini API
const callGemini = async (prompt, apiKey, model = "gemini-2.0-flash", jsonMode = false) => {
  // Map internal model names to API model names if necessary, or use direct
  // Assuming model passed is like 'gemini-2.0-flash'
  const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`;

  let finalPrompt = prompt;
  if (jsonMode) {
    finalPrompt += "\n\nIMPORTANT: Return ONLY valid JSON.";
  }

  const requestBody = {
    contents: [{
      parts: [{
        text: finalPrompt
      }]
    }]
  };

  try {
    const response = await fetch(API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestBody)
    });

    if (!response.ok) {
      const errorData = await response.text();
      throw new Error(`Gemini API Error (${response.status}): ${errorData}`);
    }

    const data = await response.json();

    let content = data.candidates?.[0]?.content?.parts?.[0]?.text;

    if (!content) {
      console.error("Unknown response structure:", JSON.stringify(data, null, 2));
      throw new Error("Empty or unknown response structure from Gemini API");
    }

    return content;

  } catch (error) {
    console.error("Gemini API Call Failed:", error);
    throw error;
  }
};

// Helper function to call Anthropic API
const callAnthropic = async (prompt, apiKey, model, jsonMode = false) => {
  try {
    // Se o modelo n√£o for passado ou for inv√°lido, o ClaudeService usa o default (Sonnet 4.5)
    const claude = new ClaudeService(apiKey, model);

    let finalPrompt = prompt;
    if (jsonMode) {
      finalPrompt += "\n\nIMPORTANT: Return ONLY valid JSON.";
    }

    const response = await claude.message(finalPrompt, {
      maxTokens: 4096,
      temperature: 0.7
    });

    return response;
  } catch (error) {
    console.error("Anthropic API Call Failed:", error);
    throw error;
  }
};

const analyzeChatConversation = async (req, res) => {
  const { messages, provider = 'openai', model } = req.body;
  const userId = req.user ? req.user.id : null; // Get from auth middleware
  const apiKey = await getEffectiveApiKey(provider, userId);

  if (!apiKey) return res.status(500).json({ error: `${provider.toUpperCase()} API Key not configured` });

  // Validate messages input
  if (!messages || !Array.isArray(messages) || messages.length === 0) {
    console.error("‚ùå Invalid messages format received:", messages);
    return res.status(400).json({ error: "Invalid messages format. Expected non-empty array." });
  }

  const chatText = formatChatHistory(messages);

  const prompt = `
    Voc√™ √© uma IA especialista em Vendas B2B e Psicologia do Consumidor, atuando como gerente de qualidade da plataforma 'EliteConversion'.
    
    Sua miss√£o √© realizar uma META AN√ÅLISE da conversa de vendas abaixo e fornecer insights estrat√©gicos em PORTUGU√äS DO BRASIL.
    Analise profundamente:
    1. Sentimento e Inten√ß√£o do cliente.
    2. Estrat√©gias de Convers√£o utilizadas (ou perdidas).
    3. Uso de Gatilhos Mentais (Escassez, Urg√™ncia, Autoridade, etc).

    Hist√≥rico da Conversa:
    ${chatText}
    
    Retorne um objeto JSON estrito com a seguinte estrutura:
    {
      "sentiment": "positive" | "neutral" | "negative",
      "intent": "high" | "medium" | "low",
      "summary": "Resumo executivo da situa√ß√£o (max 2 frases).",
      "positivePoints": ["Ponto 1", "Ponto 2", "Ponto 3"],
      "suggestions": ["Sugest√£o 1", "Sugest√£o 2", "Sugest√£o 3"],
      "warnings": ["Aviso 1", "Aviso 2", "Aviso 3"]
    }
  `;

  try {
    console.log(`üîç Starting Chat Analysis using ${provider} (${model || 'default'})...`);

    let text;
    if (provider === 'gemini') {
      text = await callGemini(prompt, apiKey, model, false);
    } else if (provider === 'anthropic') {
      text = await callAnthropic(prompt, apiKey, model, false);
    } else {
      text = await callOpenAI(prompt, apiKey, model, false);
    }

    console.log("üì© Raw AI Response for Analysis:", text);

    // Robust JSON extraction
    if (typeof text !== 'string') {
      text = JSON.stringify(text);
    }
    let cleanText = text.trim();

    // Try to find JSON block if wrapped in markdown
    const jsonMatch = cleanText.match(/```json\n?([\s\S]*?)\n?```/);
    if (jsonMatch && jsonMatch[1]) {
      cleanText = jsonMatch[1].trim();
    } else {
      // If no markdown, try to find the first '{' and last '}'
      const firstBrace = cleanText.indexOf('{');
      const lastBrace = cleanText.lastIndexOf('}');
      if (firstBrace !== -1 && lastBrace !== -1) {
        cleanText = cleanText.substring(firstBrace, lastBrace + 1);
      }
    }

    console.log("üßπ Cleaned JSON Text:", cleanText);

    const jsonResponse = JSON.parse(cleanText);
    console.log("‚úÖ Analysis Parsed Successfully");
    res.json(jsonResponse);

  } catch (error) {
    console.error("‚ùå Analysis Failed:", error);
    // Fallback: return a valid structure even on error to avoid frontend crash
    res.status(200).json({
      sentiment: "neutral",
      intent: "unknown",
      summary: "N√£o foi poss√≠vel analisar a conversa devido a um erro t√©cnico.",
      positivePoints: [],
      suggestions: ["Tente novamente mais tarde."],
      warnings: ["Erro na an√°lise IA"]
    });
  }
};

const generateMarketingContent = async (req, res) => {
  const request = req.body;
  const provider = request.provider || 'openai';
  const model = request.model;
  const userId = req.user ? req.user.id : null;
  const apiKey = await getEffectiveApiKey(provider, userId);

  if (!apiKey) return res.status(500).json({ error: `${provider.toUpperCase()} API Key not configured` });

  let typeDescription = "";
  switch (request.type) {
    case 'ad': typeDescription = "An√∫ncio Pago (Ads) focado em convers√£o direta."; break;
    case 'post': typeDescription = "Post Org√¢nico para Feed com foco em engajamento."; break;
    case 'reels': typeDescription = "Roteiro para V√≠deo Curto (Reels/TikTok) com hooks visuais."; break;
    case 'stories': typeDescription = "Sequ√™ncia de 3 Stories com narrativa envolvente."; break;
    case 'carousel': typeDescription = "Estrutura de Carrossel (Slide a Slide) educativo."; break;
    case 'poll': typeDescription = "Pergunta para Enquete com op√ß√µes interativas."; break;
    case 'article': typeDescription = "Artigo de Blog otimizado para SEO."; break;
    default: typeDescription = "Post de Marketing Digital.";
  }

  const prompt = `
      Voc√™ √© um Copywriter de Elite de classe mundial (n√≠vel Ogilvy/Gary Halbert).
      
      TAREFA: Criar conte√∫do de marketing de alta convers√£o.
      FORMATO: ${typeDescription}
      PLATAFORMA: ${request.platform}
      T√ìPICO/PRODUTO: ${request.topic}
      TOM DE VOZ: ${request.tone}
      IDIOMA: Portugu√™s do Brasil (PT-BR)
      CLIENTE_ID: ${request.clientId || 'N/A'}

      REGRAS:
      1. Use gatilhos mentais (urg√™ncia, escassez, prova social).
      2. Se for Reels, forne√ßa um roteiro visual passo a passo.
      3. Se for Carrossel, separe por Slides.
      4. Se for Blog, use H2 e H3.
      5. Gere 3 op√ß√µes de Headlines (T√≠tulos).
      6. Sugira uma ideia visual clara para a imagem/v√≠deo.

      Retorne JSON estrito com a seguinte estrutura:
      {
        "headlines": ["Titulo 1", "Titulo 2", "Titulo 3"],
        "body": "Texto do conte√∫do...",
        "cta": "Chamada para a√ß√£o...",
        "hashtags": ["#tag1", "#tag2"],
        "imageIdea": "Descri√ß√£o da imagem/v√≠deo..."
      }
  `;

  try {
    let text;
    if (provider === 'gemini') {
      text = await callGemini(prompt, apiKey, model, true);
    } else if (provider === 'anthropic') {
      text = await callAnthropic(prompt, apiKey, model, true);
    } else {
      text = await callOpenAI(prompt, apiKey, model, true);
    }

    const cleanText = text.replace(/```json\n?|\n?```/g, '').trim();
    res.json(JSON.parse(cleanText));
  } catch (error) {
    console.error("Content Generation Failed:", error);
    res.status(500).json({ error: "Failed to generate content" });
  }
};

const churnController = require('./churnController');

// ... (existing code)

const askEliteAssistant = async (req, res) => {
  const { history, question, provider = 'openai', model, clientId } = req.body;
  const userId = req.user ? req.user.id : null;
  const apiKey = await getEffectiveApiKey(provider, userId);

  if (!apiKey) {
    return res.json({ answer: "‚ö†Ô∏è **Configura√ß√£o Necess√°ria:** A chave da API (OpenAI/Gemini/Anthropic) n√£o foi encontrada no sistema backend. Por favor, verifique o arquivo `.env`." });
  }

  // Validate history parameter
  if (!history || !Array.isArray(history)) {
    return res.status(400).json({ error: "Invalid history parameter" });
  }

  // Fetch Churn Risk Context if Client ID is provided
  let churnContext = "";
  if (clientId) {
    try {
      const riskData = await churnController.calculateRiskForClient(clientId);
      if (riskData) {
        churnContext = `
        üö® **ALERTA DE RISCO DE CHURN DETECTADO** üö®
        - N√≠vel de Risco: ${riskData.riskLevel} (Score: ${riskData.riskScore}/100)
        - Fatores de Risco: ${riskData.factors.join(', ')}
        
        ‚ö†Ô∏è **INSTRU√á√ÉO CR√çTICA DE RETEN√á√ÉO:**
        Este cliente est√° em risco de cancelamento. Sua prioridade M√ÅXIMA √© ser emp√°tico, resolver problemas imediatamente e evitar atritos.
        Se o risco for CRITICAL ou HIGH, ofere√ßa atendimento priorit√°rio ou descontos se tiver autonomia (simule que tem).
        `;
      }
    } catch (err) {
      console.warn("Failed to fetch churn risk for context:", err);
    }
  }

  // --- SYMBIOSIS: FINANCIAL ADVISOR ---
  // Buscar snapshot financeiro do m√™s atual para dar contexto ao Agente
  let financialContext = "";
  try {
    const startOfMonth = new Date(new Date().getFullYear(), new Date().getMonth(), 1).toISOString().split('T')[0];
    const endOfMonth = new Date(new Date().getFullYear(), new Date().getMonth() + 1, 0).toISOString().split('T')[0];

    // SAAS FIX: Use tenant_id from user object instead of user_id
    // Assuming req.user has tenant_id (injected by auth middleware)
    const { isSuperAdmin, tenantId } = getTenantScope(req);

    if (tenantId && !isSuperAdmin) {
      // Financial data is in OPS DB (Maglev)
      const finRes = await db.opsPool.query(`
            SELECT 
                SUM(CASE WHEN type = 'income' AND status = 'paid' THEN amount ELSE 0 END) as total_income,
                SUM(CASE WHEN type = 'expense' AND status = 'paid' THEN amount ELSE 0 END) as total_expense
            FROM financial_transactions
            WHERE tenant_id = $1 AND date >= $2 AND date <= $3
        `, [tenantId, startOfMonth, endOfMonth]);

      if (finRes.rows.length > 0) {
        const f = finRes.rows[0];
        const balance = f.total_income - f.total_expense;
        financialContext = `
            üí∞ **CONTEXTO FINANCEIRO (M√™s Atual):**
            - Receita Confirmada: R$ ${parseFloat(f.total_income).toFixed(2)}
            - Despesas Pagas: R$ ${parseFloat(f.total_expense).toFixed(2)}
            - Saldo do M√™s: R$ ${balance.toFixed(2)}
            
            Se o usu√°rio perguntar sobre finan√ßas, use estes dados exatos.
            `;
      }
    }
  } catch (err) {
    console.warn("Failed to fetch financial context:", err);
  }

  const conversationContext = history.map(msg =>
    `${msg.sender === 'client' ? 'Usu√°rio' : 'Assistente'}: ${msg.text}`
  ).join('\n');

  // --- RAG: KNOWLEDGE BASE SEARCH ---
  let ragContext = "";
  try {
    const queryVector = await generateEmbeddings(question, apiKey);
    if (queryVector) {
      const searchResult = await qdrantService.searchVectors('marketing_strategies', queryVector, 3);
      if (searchResult.success && searchResult.results.length > 0) {
        const docs = searchResult.results.map(r => r.payload.content || r.payload.text).join("\n\n");
        ragContext = `
        üìö **BASE DE CONHECIMENTO (RAG):**
        Use estas informa√ß√µes internas para enriquecer sua resposta:
        ${docs}
        `;
        console.log("üìö RAG Context injected into Chat Assistant");
      }
    }
  } catch (ragErr) {
    console.warn("RAG Search failed:", ragErr.message);
  }

  // --- INTERNET ACCESS CONTROL ---
  let internetContext = "";
  if (req.body.internetAccess) {
    internetContext = `
      üåç **ACESSO √Ä INTERNET: ATIVO**
      Voc√™ tem permiss√£o para usar seu amplo conhecimento de treinamento para responder sobre tend√™ncias de mercado, not√≠cias gerais e fatos externos.
      Combine isso com os dados internos para uma resposta completa.
      `;
  } else {
    internetContext = `
      üîí **ACESSO √Ä INTERNET: DESATIVADO (MODO RESTRITO)**
      Responda APENAS com base nos dados fornecidos no Contexto Interno (Financeiro, Risco de Churn, Base de Conhecimento RAG).
      Se a resposta n√£o estiver nos dados, diga "N√£o tenho informa√ß√µes internas suficientes para responder a isso".
      N√ÉO invente fatos externos.
      `;
  }

  const prompt = `
    Voc√™ √© o **Elite Strategist**, um Especialista S√™nior em Marketing Digital e Vendas da plataforma 'EliteFinder'.
    
    ${churnContext}
    ${financialContext}
    ${ragContext}
    ${internetContext}

    üß† **SUAS ESPECIALIDADES:**
    1. **Tr√°fego Pago:** Estrat√©gias avan√ßadas para Google Ads, Meta Ads (Facebook/Instagram), LinkedIn Ads e TikTok Ads.
    2. **Social Media:** Cria√ß√£o de calend√°rios editoriais, roteiros para Reels/TikTok, e estrat√©gias de engajamento.
    3. **Copywriting:** Escrita persuasiva para an√∫ncios, landing pages e e-mails (AIDA, PAS, etc).
    4. **Funis de Vendas:** Otimiza√ß√£o de convers√£o (CRO) e jornadas do cliente.

    üéØ **DIRETRIZES DE RESPOSTA:**
    - Atue como um consultor experiente: seja estrat√©gico, direto e pr√°tico.
    - Quando o usu√°rio pedir ideias, forne√ßa listas estruturadas (ex: "3 Ideias de Hooks para Reels").
    - Se perguntarem sobre m√©tricas, explique o que significam (CTR, ROAS, CPA) e qual o benchmark ideal.
    - Responda sempre em **Portugu√™s do Brasil** com tom profissional mas acess√≠vel.

    Contexto da Conversa Atual:
    ${conversationContext}

    Nova Pergunta do Usu√°rio:
    ${question}
  `;

  try {
    let text;
    if (provider === 'gemini') {
      text = await callGemini(prompt, apiKey, model, false);
    } else if (provider === 'anthropic') {
      text = await callAnthropic(prompt, apiKey, model, false);
    } else {
      text = await callOpenAI(prompt, apiKey, model, false);
    }
    res.json({ answer: text });
  } catch (error) {
    console.error("Chat Assistant Failed:", error);
    res.status(500).json({ error: "Failed to get answer from AI" });
  }
};

/**
 * Internal function to analyze conversation strategy
 */
const analyzeStrategyInternal = async (messages, agentContext, apiKey) => {
  const prompt = `
        Atue como um Diretor de Estrat√©gia Comercial e Marketing S√™nior. Analise a seguinte conversa entre um Agente (Bot) e um Cliente (Prospect).
        
        CONTEXTO DO AGENTE:
        ${JSON.stringify(agentContext || {})}

        HIST√ìRICO DA CONVERSA:
        ${messages.map(m => `${m.role === 'user' ? 'CLIENTE' : 'AGENTE'}: ${m.content}`).join('\n')}

        TAREFA:
        Realize uma an√°lise em tempo real para fornecer "Coaching de Vendas" imediato.
        Identifique o sentimento, obje√ß√µes ocultas e sugira a pr√≥xima melhor a√ß√£o.

        Gere um relat√≥rio estrat√©gico estruturado em JSON com os seguintes campos:
        1. "sentiment": Sentimento atual do cliente (Positivo, Neutro, C√©tico, Irritado).
        2. "detected_objections": Lista de obje√ß√µes identificadas (ex: Pre√ßo, Concorr√™ncia, Autoridade).
        3. "buying_stage": Est√°gio de compra (Curiosidade, Considera√ß√£o, Decis√£o).
        4. "suggested_strategy": Uma estrat√©gia t√°tica para o vendedor usar AGORA (ex: "Use a t√©cnica de Espelhamento e foque na dor X").
        5. "next_best_action": A pr√≥xima pergunta ou afirma√ß√£o exata que deve ser feita para avan√ßar a venda.
        6. "coach_whisper": Uma dica curta e direta para o vendedor (ex: "Cuidado, ele est√° comparando com o concorrente Y, destaque nosso suporte").

        Responda APENAS o JSON.
        `;

  const text = await callOpenAI(prompt, apiKey, "gpt-4-turbo-preview", true);
  const cleanText = text.replace(/```json\n?|\n?```/g, '').trim();
  return JSON.parse(cleanText);
};

/**
 * Analisa uma conversa e gera insights estrat√©gicos de Vendas e Marketing
 */
const analyzeConversationStrategy = async (req, res) => {
  const { messages, agentContext } = req.body;
  const provider = 'openai';
  const userId = req.user ? req.user.id : null;
  const apiKey = await getEffectiveApiKey(provider, userId);

  try {
    const analysis = await analyzeStrategyInternal(messages, agentContext, apiKey);
    res.json(analysis);
  } catch (error) {
    console.error('Error analyzing strategy:', error);
    res.status(500).json({ error: 'Failed to analyze conversation' });
  }
};

/**
 * Gera uma configura√ß√£o completa de agente baseada em uma descri√ß√£o simples
 */
const generateAgentConfig = async (req, res) => {
  const { description, provider = 'openai' } = req.body;
  const userId = req.user ? req.user.id : null;
  const apiKey = await getEffectiveApiKey(provider, userId);

  if (!description) {
    return res.status(400).json({ error: 'Description is required' });
  }

  // --- RAG: KNOWLEDGE BASE SEARCH FOR AGENT CONTEXT ---
  let knowledgeContext = "";
  try {
    const queryVector = await generateEmbeddings(description, apiKey);
    if (queryVector) {
      const searchResult = await qdrantService.searchVectors('marketing_strategies', queryVector, 3);
      if (searchResult.success && searchResult.results.length > 0) {
        const docs = searchResult.results.map(r => r.payload.content || r.payload.text).join("\n\n");
        knowledgeContext = `
        üìö **CONHECIMENTO INTERNO RELEVANTE ENCONTRADO:**
        O usu√°rio possui os seguintes documentos na base de conhecimento que parecem relevantes para este agente.
        Tente incorporar as regras ou informa√ß√µes chave destes textos no "system prompt" do agente gerado:
        ${docs.substring(0, 2000)}... (truncado)
        `;
        console.log("üìö RAG Context injected into Agent Builder");
      }
    }
  } catch (ragErr) {
    console.warn("Agent Builder RAG Search failed:", ragErr.message);
  }

  const prompt = `
    Voc√™ √© um Arquiteto de Agentes de IA Especialista.
    Sua tarefa √© criar uma configura√ß√£o t√©cnica completa para um Agente de IA com base na seguinte descri√ß√£o do usu√°rio:
    
    DESCRI√á√ÉO DO USU√ÅRIO: "${description}"

    ${knowledgeContext}

    Gere um JSON estrito com a seguinte estrutura exata, preenchendo os campos de forma criativa e profissional:

    {
      "identity": {
        "name": "Nome criativo do agente",
        "category": "sales",
        "description": "Descri√ß√£o curta da fun√ß√£o do agente",
        "class": "SalesAgent",
        "specializationLevel": 5,
        "status": "active"
      },
      "aiConfig": {
        "provider": "openai",
        "model": "gpt-4-turbo-preview",
        "temperature": 0.7,
        "topP": 0.9,
        "maxTokens": 1000,
        "responseMode": "balanced"
      },
      "prompts": {
        "system": "Um prompt de sistema detalhado e robusto (min 3 par√°grafos) que defina a persona, regras de neg√≥cio, o que fazer e o que N√ÉO fazer. Use markdown.",
        "responseStructure": "Instru√ß√µes sobre como estruturar a resposta (ex: usar t√≥picos, ser conciso).",
        "analysis": "Instru√ß√µes para an√°lise de input do usu√°rio."
      }
    }

    Responda APENAS o JSON. Sem blocos de c√≥digo markdown.
    `;

  try {
    // Usar callOpenAI com jsonMode=true para garantir JSON v√°lido
    const text = await callOpenAI(prompt, apiKey, "gpt-4-turbo-preview", true);

    const cleanText = text.replace(/```json\n?|\n?```/g, '').trim();
    const config = JSON.parse(cleanText);

    res.json(config);

  } catch (error) {
    console.error('Error generating agent config:', error);
    res.status(500).json({ error: 'Failed to generate configuration' });
  }
};

const saveAnalysis = async (req, res) => {
  const { messages, analysis, provider, model } = req.body;

  try {
    const result = await db.query(
      'INSERT INTO chat_analyses (messages, analysis, provider, model) VALUES ($1, $2, $3, $4) RETURNING *',
      [JSON.stringify(messages), JSON.stringify(analysis), provider, model]
    );
    res.json(result.rows[0]);
  } catch (error) {
    console.error('Error saving analysis:', error);
    res.status(500).json({ error: 'Failed to save analysis' });
  }
};

const generateContentIdeasFromChat = async (req, res) => {
  const { provider = 'openai', limit = 50 } = req.body;
  const userId = req.user ? req.user.id : null;
  const { isSuperAdmin, tenantId } = getTenantScope(req);
  const apiKey = await getEffectiveApiKey(provider, userId);

  if (!apiKey) return res.status(500).json({ error: "API Key not configured" });

  try {
    // SAAS FIX: Filter messages by Tenant ID to prevent data leak
    // Join chat_messages -> leads -> clients -> tenant_id
    let query = `
      SELECT cm.content 
      FROM chat_messages cm
      JOIN leads l ON cm.lead_id = l.id
      JOIN clients c ON l.client_id = c.id
      WHERE cm.role = 'user' 
    `;
    let params = [limit];

    if (!isSuperAdmin && tenantId) {
      query += ` AND c.tenant_id = $2`;
      params.push(tenantId);
    }

    query += ` ORDER BY cm.created_at DESC LIMIT $1`;

    const result = await db.query(query, params);

    if (result.rows.length === 0) {
      return res.json({ ideas: [] });
    }

    const messagesText = result.rows.map(r => r.content).join("\n");

    // 2. Analyze and Generate Ideas
    const prompt = `
      Atue como um Estrategista de Conte√∫do.
      Analise as seguintes mensagens recentes de clientes/leads:
      
      "${messagesText}"

      TAREFA:
      1. Identifique as 3 principais dores, d√∫vidas ou desejos recorrentes.
      2. Para cada uma, gere uma ideia de Post para Instagram/LinkedIn que resolva essa d√∫vida.

      Retorne um JSON estrito:
      {
        "analysis": "Resumo das tend√™ncias identificadas...",
        "ideas": [
          {
            "title": "T√≠tulo do Post",
            "format": "Reels/Carrossel/Static",
            "hook": "A frase inicial para prender a aten√ß√£o",
            "description": "Breve descri√ß√£o do conte√∫do"
          }
        ]
      }
    `;

    const text = await callOpenAI(prompt, apiKey, "gpt-4-turbo-preview", true);
    const cleanText = text.replace(/```json\n?|\n?```/g, '').trim();

    res.json(JSON.parse(cleanText));

  } catch (error) {
    console.error("Content Ideas Generation Failed:", error);
    res.status(500).json({ error: "Failed to generate ideas" });
  }
};

const startBatchGeneration = async (req, res) => {
  const { days, topics, platform, tone, targetAudience, provider = 'openai', clientId } = req.body;
  const user_id = req.user ? req.user.id : null;
  const { tenantId } = getTenantScope(req);
  const { jobsQueue } = require('./queueClient'); // Ensure this imports correctly

  try {
    // 1. Create Batch Record
    const batchResult = await db.query(
      `INSERT INTO content_batches (user_id, topic, total_days, platform, tone, settings, status) 
       VALUES ($1, $2, $3, $4, $5, $6, 'processing') 
       RETURNING id`,
      [user_id, JSON.stringify(topics), days, platform, tone, JSON.stringify(targetAudience)]
    );
    const batchId = batchResult.rows[0].id;

    console.log(`üöÄ Starting Batch Generation ${batchId} for ${days} days`);

    // 2. Add Job to Queue (One job per day/topic to parallelize)
    const jobs = topics.map((dailyTopic, index) => ({
      name: 'generate_batch_content',
      data: {
        type: 'generate_batch_content',
        payload: {
          batchId,
          dayIndex: index + 1,
          topic: dailyTopic,
          platform,
          tone,
          targetAudience,
          provider,
          userId: user_id,
          tenantId,
          clientId
        }
      }
    },
      opts: {
      jobId: `batch_${batchId}_day_${index + 1}`
    }
    }));

  // Add all jobs to queue
  // Check if jobsQueue exists and has addBulk
  if (jobsQueue && jobsQueue.addBulk) {
    await jobsQueue.addBulk(jobs);
  } else {
    console.warn("‚ö†Ô∏è jobsQueue not available, falling back to sequential add or error.");
    // Fallback if needed, but assuming it works for now based on project structure
  }

  res.json({
    success: true,
    batchId,
    message: `Batch iniciada! ${days} posts sendo gerados em segundo plano.`
  });

} catch (error) {
  console.error('Batch Generation Start Failed:', error);
  res.status(500).json({ error: 'Failed to start batch generation' });
}
};

module.exports = {
  analyzeChatConversation,
  generateMarketingContent,
  askEliteAssistant,
  analyzeConversationStrategy,
  generateAgentConfig,
  saveAnalysis,
  generateDashboardInsights,
  analyzeStrategyInternal,
  getEffectiveApiKey,
  generateContentIdeasFromChat,
  startBatchGeneration
};
